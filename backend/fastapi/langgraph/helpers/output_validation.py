from langchain_core.messages import HumanMessage
from loguru import logger
from .graph_state_classes import BusinessOnlyState, BusinessValidationResult
from .model_config import fetch_model_from_ollama


def create_business_validation_prompt(original_prompt: str, generated_business: BusinessOnlyState) -> str:
    """
    Returns a prompt to validate whether the business generator's output is acceptable or not.

    :param original_prompt: the prompt that was passed to the business generator
    :param generated_business: the structured business state/object that was populated by the business generator
    :return: a dict with details about why or why not the business is acceptable
    """
    return f"""
        You are a business analyst. Decide if the following business matches the requirements.

        PROMPT:
        {original_prompt}

        BUSINESS:
        Name: {generated_business.business_name}
        Location: {generated_business.business_location}
        Contact: {generated_business.business_contact_info}
        Activity: {generated_business.business_activity}
        Description: {generated_business.business_description}

        Reply in this JSON format:
        {{
          "is_valid": true or false,
          "reason": "short explanation"
        }}
    """


def validate_business_output(
    original_prompt: str,
    generated_business: BusinessOnlyState,
    llm_model_name: str = "llama3.2"
) -> BusinessValidationResult:
    """
    Validates whether the business generated is acceptable or not.
    :param original_prompt: the prompt passed to the business generator
    :param generated_business: the structured business/state generated by the business generator
    :param llm_model_name: the name of the model based on the ollama model registry
    :return: whether the model's response is acceptable or note
    """

    prompt = create_business_validation_prompt(original_prompt, generated_business)
    ollama_llm = fetch_model_from_ollama(llm_model_name)
    ollama_llm_with_structured_output = ollama_llm.with_structured_output(BusinessValidationResult)

    try:
        return ollama_llm_with_structured_output.invoke([HumanMessage(content=prompt)])
    except Exception as e:
        logger.error(f"Validation failed: {e}")
        return BusinessValidationResult(is_valid=False, reason="Validation error")
